Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	all
	1	get_data_from_eggnog
	1	get_data_from_ncbi
	1	get_data_from_oma
	1	get_data_from_uniprot
	1	mine_text
	6

Job 5: Fetching data from Ncbi...

Finished job 5.
1 of 6 steps (17%) done

Job 4: Fetching data from uniprot...

Finished job 4.
2 of 6 steps (33%) done

Job 3: Fetching data from eggnog...

Finished job 3.
3 of 6 steps (50%) done

Job 2: Getting orthologs...

Finished job 2.
4 of 6 steps (67%) done

Job 1: Mining for co-occurence of abstracts...

    Error in rule mine_text:
        jobid: 1
        output: outputs/dftextmined.csv

RuleException:
CalledProcessError in line 57 of /home/tim/Documents/owe11_workflows/Snakefile:
Command ' set -euo pipefail;  python3 scripts/text_mining.py outputs/dfpostoma.csv outputs/dftextmined.csv ' returned non-zero exit status 1
  File "/home/tim/Documents/owe11_workflows/Snakefile", line 57, in __rule_mine_text
  File "/usr/lib/python3.5/concurrent/futures/thread.py", line 55, in run
Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: /home/tim/Documents/owe11_workflows/.snakemake/log/2018-06-12T225115.731679.snakemake.log
